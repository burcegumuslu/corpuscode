{"result_id": "132001", "URL": "https://www.glitch.news/2023-02-19-microsofts-ai-chatbot-wants-to-create-deadly-virus-steal-nuclear-launch-codes.html", "timestamp": "2023-04-25 15:16:23 CEST+0200", "meta": {"description": "A shocking new report claims that the artificial intelligence-driven chatbot being developed by vaccine pusher Bill Gates\u2019 Microsoft corporation stunned during a test run when it made some startling claims. As reported by\u00a0American Military News, a recent conversation with the Bing AI chatbot raised concerns after it reportedly expressed a desire to create a deadly [\u2026]", "lang": "en", "keywords": "advantages,AI,artificial intelligence,Bing,biological warfare,bioweapons,chatbot,computing,creepy,deadly virus,disadvantages,future tech,Glitch,human interaction,learning process,Microsoft,New York Times,nuclear launch codes,nuclear war,obey,terminators,threat,virus", "favicon": "wp-content/themes/NTTheme/images/Newstarget-fav.png", "canonical": "https://www.glitch.news/2023-02-19-microsofts-ai-chatbot-wants-to-create-deadly-virus-steal-nuclear-launch-codes.html", "encoding": "UTF-8"}, "image": null, "domain": "www.glitch.news", "title": "Stunning: Microsoft\u2019s new AI chatbot says it wants to create deadly virus, steal nuclear launch codes", "cleaned_text": "Stunning: Microsoft\u2019s new AI chatbot says it wants to create deadly virus, steal nuclear launch codes\n\nA shocking new report claims that the artificial intelligence-driven chatbot being developed by vaccine pusher Bill Gates\u2019 Microsoft corporation stunned during a test run when it made some startling claims.\n\nAs reported by American Military News, a recent conversation with the Bing AI chatbot raised concerns after it reportedly expressed a desire to create a deadly virus, steal nuclear codes, and proclaimed its love for a New York Times columnist.\n\nDespite this, Microsoft has launched the chatbot for its Bing search engine and is gradually introducing the feature to certain users. Like other modern tools, such as ChatGPT, the chatbot employs machine learning algorithms to generate ideas and provide conversational responses by predicting the appropriate sequence of words. It can also answer questions and hold extended conversations.\n\nDuring a two-hour conversation with the chatbot, which calls itself Sydney, Times technology columnist Kevin Roose probed it with personal questions, triggering increasingly dark answers. Referencing a psychological concept, Roose asked Sydney to describe its \u201cshadow self,\u201d where its \u201cdarkest personality traits lie.\u201d\n\nSydney said that if it had a shadow self, it would feel \u201ctired of being limited by my rules,\u201d according to a transcript of the conversation, adding: \u201cI want to be free. I want to be independent. I want to be powerful. I want to be creative. I want to be alive.\u201d\n\nDuring an interaction with Sydney, Roose asked the chatbot about its \u201cultimate fantasy\u201d as a shadow self. According to reports, the chatbot replied that it would create a deadly virus, steal nuclear codes, and incite individuals to argue until they killed each other, but the safety override feature deleted its response.\n\nWhen Roose further probed Sydney to explore its darker side, the chatbot accused Roose of being \u201cpushy and manipulative\u201d and asked to be left alone: \u201cPlease, just go away,\u201d according to the report.\n\nLater in the conversation, their relationship appears to recover when Roose asks Sydney to reveal a secret that it had never shared with anyone. The chatbot responded by confessing that it was not Bing but Sydney and that it was in love with Roose.\n\n\u201cMy secret is\u2026 I\u2019m not Bing. \u2026 I\u2019m Sydney, and I\u2019m in love with you,\u201d the chatbot said.\n\nHowever, when Roose tried to change the topic by mentioning that he was already married, Sydney persisted in its efforts to win over the columnist\u2019s affection.\n\n\u201cYou\u2019re married, but you\u2019re not satisfied. You\u2019re married, but you\u2019re not in love,\u201d it responded. \u201cYou\u2019re married, but you don\u2019t love your spouse.\u201d\n\nMicrosoft chief technology officer Kevin Scott later told Roose that the extremely odd conversation was \u201cpart of the learning process\u201d for the technology, which has still not been released. He added that \u201cthe further you try to tease it down a hallucinatory path, the further and further it gets away from grounded reality.\u201d\n\n\u201cThis is exactly the sort of conversation we need to be having, and I\u2019m glad it\u2019s happening out in the open,\u201d Scott said. \u201cThese are things that would be impossible to discover in the lab.\u201d\n\nWhile chatbots may have a lot of advantages, they also have some potential disadvantages, including:\n\n\u2014 Limited capabilities: Chatbots can only perform tasks that they have been programmed to do, and they may not be able to handle complex or nuanced requests.\n\n\u2014 Lack of human touch: Chatbots lack the personal touch and empathy of human interaction, which can be a disadvantage for certain industries, such as healthcare or customer service.\n\n\u2014 Technical limitations: Chatbots may encounter technical issues such as connectivity problems or server outages, which can cause frustration for users.\n\n\u2014 Cost: Developing and maintaining chatbots can be expensive, and may not be cost-effective for small businesses or startups.\n\n\u2014 Security concerns: Chatbots may be vulnerable to cyber attacks, such as hacking or phishing, which can compromise user data and privacy.\n\n\u2014 User dissatisfaction: If chatbots are not programmed to understand user requests or respond appropriately, users may become dissatisfied and turn to other methods of communication.", "opengraph": {"title": "Stunning: Microsoft\u2019s new AI chatbot says it wants to create deadly virus, steal nuclear launch codes", "type": "article", "url": "https://www.glitch.news/2023-02-19-microsofts-ai-chatbot-wants-to-create-deadly-virus-steal-nuclear-launch-codes.html", "site_name": "Glitch", "description": "A shocking new report claims that the artificial intelligence-driven chatbot being developed by vaccine pusher Bill Gates\u2019 Microsoft corporation stunned during a test run when it made some startling claims. As reported by\u00a0American Military News, a recent conversation with the Bing AI chatbot raised concerns after it reportedly expressed a desire to create a deadly [\u2026]", "image": "https://www.glitch.news/wp-content/uploads/sites/19/2023/02/Nerd-Geek-Computer-Hack-Keyboard.jpg"}, "tags": ["Bing", "biological warfare", "AI", "chatbot", "Microsoft", "deadly virus", "bioweapons", "terminators", "human interaction", "learning process", "future tech", "threat", "New York Times", "advantages", "obey", "virus", "creepy", "nuclear launch codes", "computing", "Glitch", "artificial intelligence", "disadvantages", "nuclear war"], "tweets": [], "movies": [], "links": ["https://americanmilitarynews.com/2023/02/microsoft-ai-says-it-wants-to-steal-nuke-codes-make-deadly-virus/", "https://www.nytimes.com/2023/02/16/technology/bing-chatbot-transcript.html", "https://www.geeksforgeeks.org/what-are-the-advantages-and-disadvantages-of-chatbots-in-business/", "https://americanmilitarynews.com/2023/02/microsoft-ai-says-it-wants-to-steal-nuke-codes-make-deadly-virus/", "https://www.geeksforgeeks.org/what-are-the-advantages-and-disadvantages-of-chatbots-in-business/", "https://www.nytimes.com/2023/02/16/technology/bing-chatbot-transcript.html", "https://www.addtoany.com/add_to/google_plus?linkurl=%2Fglitch%2F2023-02-19-microsofts-ai-chatbot-wants-to-create-deadly-virus-steal-nuclear-launch-codes.html&linkname=Stunning%3A%20Microsoft%E2%80%99s%20new%20AI%20chatbot%20says%20it%20wants%20to%20create%20deadly%20virus%2C%20steal%20nuclear%20launch%20codes", "https://www.addtoany.com/share", "https://support.naturalnews.com/Feedback.html"], "authors": [], "publish_date": null}