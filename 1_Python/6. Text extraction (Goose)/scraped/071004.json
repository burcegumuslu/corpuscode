{"result_id": "071004", "URL": "https://judithcurry.com/2016/10/27/advocacy-research-incentives-and-the-practice-of-science/", "timestamp": "2023-04-25 14:44:09 CEST+0200", "meta": {"description": "by Judith Curry There is a problem with the practice of science. Because of poor scientific practices, and improper incentives, few papers with useful scientific findings are published in leading journals. The problem appears to be growing due to funding for advocacy research. J. Scott Armstrong and Kesten Green have written\u00a0an important new paper Guidelines\u2026", "lang": "en", "keywords": "", "favicon": "https://s0.wp.com/i/webclip.png", "canonical": "https://judithcurry.com/2016/10/27/advocacy-research-incentives-and-the-practice-of-science/", "encoding": "UTF-8"}, "image": null, "domain": "judithcurry.com", "title": "Advocacy research, incentives and the practice of science", "cleaned_text": "There is a problem with the practice of science. Because of poor scientific practices, and improper incentives, few papers with useful scientific findings are published in leading journals. The problem appears to be growing due to funding for advocacy research.\n\nJ. Scott Armstrong and Kesten Green have written an important new paper Guidelines for Science: Evidence and Checklists. I encourage you to read the whole paper.\n\nHere are some excerpts that I think are particularly important:\n\nFunding for researchers is often provided to gain support for a favored hypothesis. Researchers are also rewarded for finding evidence that supports hypotheses favored by senior colleagues. These incentives leads to what we call \u201cadvocacy research,\u201d an approach that is contrary to the definition of science. In addition, university researchers are typically rewarded with selection and promotion on the basis of their performance against measures that have the effect of distracting them from doing useful scientific research.\n\nAdvocacy research can be the product of a genuine belief that one\u2019s preferred hypothesis must be true, thus blinding the researcher to alternatives. The single-minded pursuit of support for a favored hypothesis has also been referred to as \u201cconfirmation bias\u201d. The inability to consider alternatives appears to be a common problem even for scientists. Journal reviewers often act as advocates by recommending the rejection of papers that challenge popular theories.\n\nResearchers in universities are typically subject to incentives that are unrelated to or detrimental to Franklin\u2019s call for useful research. In particular, university administrators reward researchers for obtaining grants and other funding, and for publishing papers in high-status journals.\n\nThere is little reason to believe that committees of officials in governments, corporations, or foundations can and do identify projects that would lead to useful scientific findings better than individual researchers can and do. Creativity is an individual activity, and designing research projects is better left to scientists who know how best to design research projects in their own area of expertise.\n\nObtaining funding is an expensive exercise, and this reduces the money and time researchers have available for doing useful research. Finally, if you do succeed in obtaining funding, you are likely to lose some freedom as we discuss below\n\nThe number of papers published in academic journals is a poor measure of useful scientific output. Many papers address trivial problems.\n\nArmstrong and Hubbard (1991) conducted a survey of editors of American Psychological Association (APA) journals that asked: \u201cTo the best of your memory, during the last two years of your tenure as editor of an APA journal, did your journal publish one or more papers that were considered to be both controversial and empirical? (That is, papers that presented empirical evidence contradicting the prevailing wisdom.)\u201d Sixteen of the 20 editors replied: Seven editors could recall none, four said there was one, while three said there was at least one. Two editors said that they published several such papers.\n\nFortunately, it occurs to some researchers and to some research organizations that their proper objective is to produce useful scientific findings. As a result, one can look in almost any area and find useful scientific research. Our concern in this paper is not the absence of important papers, but rather their infrequency. That concern is related to what Holub, Tappeiner, and Eberharter (1991)\u2014referring to the field of economics\u2014called the Iron Law of Important Papers: Rapid increases in government funding has increased the number of papers published but seems to have had little effect on the number of papers with useful scientific findings.\n\nThe authors present comprehensive operational guidelines for scientists. Here, I select some text that I feel makes particularly important points:\n\nThe way a problem is stated limits the search for solutions. To avoid that, state the problem in many different ways prior to searching for solutions, a technique known as \u201cproblem storming.\u201d. Then search for solutions for each problem.\n\nSkepticism drives progress in science. Unfortunately, skepticism can also annoy other researchers and thus reduce opportunities for employment, funding, publication, and citations. Researchers in universities go to considerable lengths to ensure a common core of beliefs as is witnessed by the fact that over the past half century, political conservatives have become rare in social science departments at leading U.S. universities with the consequent loss of that source of skepticism toward fashionable ideas that are at odds with established economic principles.\n\nIt does little good to try to be as objective as possible. That is too vague. The solution suggested by Francis Bacon was to consider \u201cany contrary hypotheses that may be imagined.\u201d What information would cause you to conclude that your favored hypothesis was inferior to other hypotheses? If you cannot think of any information that would threaten belief in your preferred hypothesis, work on a different problem.\n\nChamberlin (1890) observed that the fields of science that made the most progress were those that tested all reasonable hypotheses. Assess reasonableness generously, as Sir Francis Bacon suggested. The approach fosters objectivity.\n\nUsing the Guidelines for Science\n\nAdam Smith wondered why Scotland\u2019s relatively few academics were responsible for many scientific advances during the Industrial Revolution, while England\u2019s larger number of academics contributed little. He concluded that because the government provided them with generous support, academics in England had little motivation to do useful research. Modern universities around the world tend to be more like those of 18th Century England than they are like those of 18th Century Scotland. Should we expect different results?\n\nGovernments are inclined to support advocacy research and to suppress the speech of scientists who challenge that research.\n\nThere is a long history of governments\u2014civil and religious\u2014suppressing the speech of scientists when it was politically inconvenient for them to do so. In modern times, the Soviet government endorsement of Lysenko\u2019s theories led to persecution of agricultural experimenters whose findings did support those theories (Miller, 1996). Currently, some scientists whose findings conflict with the U.S. government\u2019s position on the global warming alarm have been threatened, harassed, fired from government and university positions, subjected to hacking of their websites, and threatened with prosecution under racketeering (RICO) laws (see, e.g., Curry, 2015).\n\nAccording to Burnham (1990), mandatory journal peer review was not common until sometime after World War II. Burnham concluded that mandatory journal peer review has been detrimental to science. The evidence supports Burnham. Consider that reviewers fail to reliably identify errors in papers. For example, Baxt, Waeckerie, Berlin, and Callaham (1998) sent a fictitious paper with 10 major and 13 minor errors to 262 reviewers. Of that number, 199 submitted reviews. On average, the reviewers identified only 23 percent of the errors. They missed some big errors; for example, 68 percent of the reviewers did not realize that the results did not support the conclusions.\n\nIn a similar study, Schroter et al. (2008) gave \u201cjournal reviewers\u201d papers containing nine major intentional errors. The typical reviewer found only 2.6 (29 percent) of the errors. But most important is the evidence presented in their paper that reviewers seldom assess whether submitted papers present useful scientific findings.\n\nThe essay by Armstrong and Green is provocative on numerous fronts. I have a few overarching comments.\n\nFirst, I think that their definitions of science, scientific method and forecasting put forward are somewhat narrow, when the natural/physical sciences are considered (it may be appropriate for the social sciences). See in particular these previous essays at CE:\n\nI think the issue, and definition, of \u2018advocacy science\u2019 is important. It seems that far too much of climate research (including what is funded by the U.S. government) falls into this bucket.\n\nThe issue of incentives for researchers is a huge problem, which was discussed most recently at CE in this post:\n\nI like the \u2018problem storming\u2019 idea. I explicitly adopted the \u2018multiple working hypotheses\u2019 strategy in my paper Mixing Politics and Science in Testing the Hypothesis That Greenhouse Warming Is Causing a Global Increase in Hurricane Intensity. Unfortunately, natural variability is treated as insignificant noise in way too many climate science papers.\n\nWith regards to the research checklist, I think there are some good ideas and important points there. However, I find it to be overly constraining and formulaic for natural/physical sciences, particularly with regards to Bohr\u2019s Quadrant.\n\nAnd finally, specifically with regards to climate science, I think that the coupled advocacy and incentives issues raised here are very important and need to be more widely recognized in policy making, not to mention assessment reports.", "opengraph": {"type": "article", "title": "Advocacy research, incentives and the practice of science", "url": "https://judithcurry.com/2016/10/27/advocacy-research-incentives-and-the-practice-of-science/", "description": "by Judith Curry There is a problem with the practice of science. Because of poor scientific practices, and improper incentives, few papers with useful scientific findings are published in leading j\u2026", "article:published_time": "2016-10-27T15:04:45+00:00", "article:modified_time": "2016-10-27T15:04:45+00:00", "site_name": "Climate Etc.", "image": "https://s0.wp.com/i/blank.jpg", "locale": "en_US"}, "tags": [], "tweets": [], "movies": [], "links": ["https://www.researchgate.net/publication/305712994_Guidelines_for_Science_Evidence_and_Checklists", "https://judithcurry.com/2010/11/09/the-scientific-method/", "https://judithcurry.com/2012/05/31/what-separates-science-from-non-science/", "https://judithcurry.com/2016/07/15/the-troubled-institution-of-science/", "http://curry.eas.gatech.edu/currydoc/Curry_BAMS87.pdf", "https://judithcurry.com/2013/05/15/pasteurs-quadrant/", "mailto:?subject=%5BShared%20Post%5D%20Advocacy%20research%2C%20incentives%20and%20the%20practice%20of%20science&body=https%3A%2F%2Fjudithcurry.com%2F2016%2F10%2F27%2Fadvocacy-research-incentives-and-the-practice-of-science%2F&share=email", "https://judithcurry.com/2016/10/27/advocacy-research-incentives-and-the-practice-of-science/?share=twitter", "https://judithcurry.com/2016/10/27/advocacy-research-incentives-and-the-practice-of-science/?share=facebook", "https://judithcurry.com/2016/10/27/advocacy-research-incentives-and-the-practice-of-science/#print", "https://judithcurry.com/2016/10/27/advocacy-research-incentives-and-the-practice-of-science/?share=reddit", "https://judithcurry.com/2016/10/27/advocacy-research-incentives-and-the-practice-of-science/?share=tumblr"], "authors": [], "publish_date": "2016-10-27T15:04:45+00:00"}